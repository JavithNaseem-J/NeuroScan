{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff4b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755ec8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3337983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc84a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    model_path: str\n",
    "    train_gen_path: str\n",
    "    val_gen_path: str\n",
    "    mlflow_uri: str\n",
    "    experiment_name: str\n",
    "    input_shape: list\n",
    "    num_classes: int\n",
    "    learning_rate: float\n",
    "    epochs: int\n",
    "    dropout_rate: float\n",
    "    loss: str\n",
    "    monitor: str\n",
    "    patience: int\n",
    "    reduce_lr_factor: float\n",
    "    reduce_lr_patience: int\n",
    "    reduce_lr_min_delta: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcfdd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuroScan.utils.helpers import *\n",
    "from NeuroScan.constants.paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1312f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfigurationManager:\n",
    "    def __init__(self, config_file=CONFIG_PATH, params_file=PARAMS_PATH):\n",
    "        self.config = read_yaml(config_file)\n",
    "        self.params = read_yaml(params_file)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.model_params\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        return ModelTrainerConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            model_path=config.model_path,\n",
    "            mlflow_uri=config.mlflow_uri,\n",
    "            experiment_name=config.experiment_name,\n",
    "            input_shape=params.input_shape,\n",
    "            num_classes=params.num_classes,\n",
    "            learning_rate=params.learning_rate,\n",
    "            epochs=params.epochs,\n",
    "            dropout_rate=params.dropout_rate,\n",
    "            loss=params.loss,\n",
    "            monitor=params.monitor,\n",
    "            patience=params.patience,\n",
    "            reduce_lr_factor=params.reduce_lr_factor,\n",
    "            reduce_lr_patience=params.reduce_lr_patience,\n",
    "            reduce_lr_min_delta=params.reduce_lr_min_delta,\n",
    "            train_gen_path=config.train_gen_path,\n",
    "            val_gen_path=config.val_gen_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb96df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from NeuroScan.utils.logging import logger\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "class ModelTrainer:\n",
    "    \n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.train_generator = None\n",
    "        self.valid_generator = None\n",
    "\n",
    "        mlflow.set_tracking_uri(self.config.mlflow_uri)\n",
    "        mlflow.set_experiment(self.config.experiment_name)\n",
    "\n",
    "        self.run = mlflow.start_run()\n",
    "        self._initialize_generators()\n",
    "\n",
    "    def _initialize_generators(self):\n",
    "        \"\"\"Initializes generators from saved files.\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.config.train_gen_path) and os.path.exists(self.config.val_gen_path):\n",
    "                logger.info(\"Loading pre-saved generators...\")\n",
    "                train_data = np.load(self.config.train_gen_path, allow_pickle=True).item()\n",
    "                val_data = np.load(self.config.val_gen_path, allow_pickle=True).item()\n",
    "                self.train_generator = tf.data.Dataset.from_tensor_slices((train_data['data'], train_data['labels'])).batch(32)  \n",
    "                self.valid_generator = tf.data.Dataset.from_tensor_slices((val_data['data'], val_data['labels'])).batch(32) \n",
    "                logger.info(\"Pre-saved generators loaded successfully.\")\n",
    "            else:\n",
    "                logger.error(\"Saved generator files not found. Please run data_transformation first.\")\n",
    "                raise FileNotFoundError(\"Generator files missing.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing generators: {e}\")\n",
    "            raise\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Constructs the model architecture.\"\"\"\n",
    "\n",
    "        try:\n",
    "            base_model = EfficientNetB1(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=tuple(self.config.input_shape)\n",
    "            )\n",
    "            model = base_model.output\n",
    "            model = GlobalMaxPooling2D()(model)\n",
    "            model = Dropout(self.config.dropout_rate)(model)\n",
    "            model = Dense(self.config.num_classes, activation=\"softmax\")(model)\n",
    "            self.model = Model(inputs=base_model.input, outputs=model)\n",
    "            self.model.compile(\n",
    "                optimizer=Adam(learning_rate=self.config.learning_rate),\n",
    "                loss=self.config.loss,\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            logger.info(\"Model architecture built and compiled successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error building model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def setup_callbacks(self):\n",
    "        \"\"\"Configures callbacks for training.\"\"\"\n",
    "\n",
    "        try:\n",
    "            checkpoint = ModelCheckpoint(\n",
    "                self.config.model_path,\n",
    "                monitor=self.config.monitor,\n",
    "                save_best_only=True,\n",
    "                mode='auto',\n",
    "                verbose=1\n",
    "            )\n",
    "            earlystop = EarlyStopping(\n",
    "                monitor=self.config.monitor,\n",
    "                patience=self.config.patience,\n",
    "                mode='auto',\n",
    "                verbose=1\n",
    "            )\n",
    "            reduce_lr = ReduceLROnPlateau(\n",
    "                monitor=self.config.monitor,\n",
    "                factor=self.config.reduce_lr_factor,\n",
    "                patience=self.config.reduce_lr_patience,\n",
    "                min_delta=self.config.reduce_lr_min_delta,\n",
    "                mode='auto',\n",
    "                verbose=1\n",
    "            )\n",
    "            return [checkpoint, earlystop, reduce_lr]\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error setting up callbacks: {e}\")\n",
    "            raise\n",
    "\n",
    "    def log_training_metrics(self, history):\n",
    "        \"\"\"Logs training metrics to MLflow.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            train_acc = np.array(history.history['accuracy'])\n",
    "            val_acc = np.array(history.history['val_accuracy'])\n",
    "            mean_train_acc = np.mean(train_acc)\n",
    "            std_train_acc = np.std(train_acc)\n",
    "            mean_val_acc = np.mean(val_acc)\n",
    "            std_val_acc = np.std(val_acc)\n",
    "            mlflow.log_metric(\"mean_train_accuracy\", mean_train_acc)\n",
    "            mlflow.log_metric(\"std_train_accuracy\", std_train_acc)\n",
    "            mlflow.log_metric(\"mean_val_accuracy\", mean_val_acc)\n",
    "            mlflow.log_metric(\"std_val_accuracy\", std_val_acc)\n",
    "            logger.info(f\"Logged training metrics: mean_train_acc={mean_train_acc:.4f}, std_train_acc={std_train_acc:.4f}, \"\n",
    "                        f\"mean_val_acc={mean_val_acc:.4f}, std_val_acc={std_val_acc:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error logging training metrics: {e}\")\n",
    "            raise\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Trains the model using pre-initialized data generators.\"\"\"\n",
    "\n",
    "        try:\n",
    "            if self.model is None:\n",
    "                self.build_model()\n",
    "\n",
    "            callbacks = self.setup_callbacks()\n",
    "            logger.info(\"Starting model training...\")\n",
    "            self.history = self.model.fit(\n",
    "                self.train_generator,\n",
    "                epochs=self.config.epochs,\n",
    "                validation_data=self.valid_generator,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            logger.info(\"Model training completed.\")\n",
    "            self.log_training_metrics(self.history)\n",
    "            mlflow.tensorflow.log_model(self.model, \"model\")\n",
    "            return self.model, self.history\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during training: {e}\")\n",
    "            raise\n",
    "\n",
    "        finally:\n",
    "            mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "        model_config = ModelConfigurationManager()\n",
    "        trainer_config = model_config.get_model_trainer_config()\n",
    "        trainer = ModelTrainer(config=trainer_config)\n",
    "        model, history = trainer.train()\n",
    "except Exception as e:\n",
    "        logger.error(f\"Model training failed: {e}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuroScan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
