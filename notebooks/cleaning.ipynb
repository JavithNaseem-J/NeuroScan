{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c3cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4df7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcefc614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from NeuroScan.utils.helpers import *\n",
    "from NeuroScan.constants.paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a032ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCleaningConfig:\n",
    "    root_dir: Path\n",
    "    source_data_dir: Path\n",
    "    image_size: int\n",
    "    target_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e717ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataConfigurationManager:\n",
    "    def __init__(self, config_file=CONFIG_PATH, params_file=PARAMS_PATH):\n",
    "        self.config = read_yaml(config_file)\n",
    "        self.params = read_yaml(params_file)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_cleaning_config(self):\n",
    "        config = self.config.cleaning\n",
    "        params = self.params.cleaning\n",
    "        create_directories([config.root_dir])\n",
    "        return DataCleaningConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            source_data_dir=Path(config.source_data_dir),\n",
    "            image_size=params.image_size,\n",
    "            target_image_size=params.target_image_size\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "529d98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import imutils\n",
    "from NeuroScan.utils.helpers import create_directories\n",
    "from NeuroScan.utils.logging import logger\n",
    "\n",
    "class DataCleaning:\n",
    "    \"\"\"Handles image preprocessing, including cropping and resizing.\"\"\"\n",
    "    def __init__(self, config: DataCleaningConfig):\n",
    "        self.config = config\n",
    "        self.classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "        self.train_dir = self.config.source_data_dir / 'Training'\n",
    "        self.test_dir = self.config.source_data_dir / 'Testing'\n",
    "        self.cropped_train_dir = self.config.root_dir / 'Crop-Brain-MRI'\n",
    "        self.cropped_test_dir = self.config.root_dir / 'Test-Data'\n",
    "\n",
    "    def validate_directories(self):\n",
    "        \"\"\"Validates that source directories exist.\"\"\"\n",
    "        try:\n",
    "            for directory in [self.train_dir, self.test_dir]:\n",
    "                if not directory.exists():\n",
    "                    logger.error(f\"Source directory {directory} does not exist.\")\n",
    "                    raise FileNotFoundError(f\"Source directory {directory} not found.\")\n",
    "                for class_name in self.classes:\n",
    "                    class_dir = directory / class_name\n",
    "                    if not class_dir.exists():\n",
    "                        logger.error(f\"Class directory {class_dir} does not exist.\")\n",
    "                        raise FileNotFoundError(f\"Class directory {class_dir} not found.\")\n",
    "            logger.info(\"All source directories validated successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Directory validation failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def crop_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Crops image to focus on the region of interest.\"\"\"\n",
    "        try:\n",
    "            img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            img_blur = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "            img_thresh = cv2.threshold(img_blur, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "            img_thresh = cv2.erode(img_thresh, None, iterations=2)\n",
    "            img_thresh = cv2.dilate(img_thresh, None, iterations=2)\n",
    "            contours = cv2.findContours(img_thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contours = imutils.grab_contours(contours)\n",
    "            if not contours:\n",
    "                logger.warning(\"No contours found in image; returning original.\")\n",
    "                return image\n",
    "            c = max(contours, key=cv2.contourArea)\n",
    "            extLeft = tuple(c[c[:, :, 0].argmin()])[0]\n",
    "            extRight = tuple(c[c[:, :, 0].argmax()])[0]\n",
    "            extTop = tuple(c[c[:, :, 1].argmin()])[0]\n",
    "            extBottom = tuple(c[c[:, :, 1].argmax()])[0]\n",
    "            cropped_img = image[extTop[1]:extBottom[1], extLeft[0]:extRight[0]]\n",
    "            return cropped_img\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cropping image: {e}\")\n",
    "            return image\n",
    "\n",
    "    def create_output_directories(self):\n",
    "        \"\"\"Creates directories for cropped training and testing images.\"\"\"\n",
    "        try:\n",
    "            create_directories([self.cropped_train_dir, self.cropped_test_dir])\n",
    "            for class_name in self.classes:\n",
    "                create_directories([\n",
    "                    self.cropped_train_dir / class_name,\n",
    "                    self.cropped_test_dir / class_name\n",
    "                ])\n",
    "            logger.info(f\"Output directories created at {self.cropped_train_dir} and {self.cropped_test_dir}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating directories: {e}\")\n",
    "            raise\n",
    "\n",
    "    def process_images(self, source_dir: Path, target_dir: Path):\n",
    "        \"\"\"Processes images by cropping and resizing, then saves to target directory.\"\"\"\n",
    "        try:\n",
    "            image_count = 0\n",
    "            for class_name in self.classes:\n",
    "                class_source = source_dir / class_name\n",
    "                class_target = target_dir / class_name\n",
    "                if not class_source.exists():\n",
    "                    logger.warning(f\"Source directory {class_source} does not exist.\")\n",
    "                    continue\n",
    "                j = 0\n",
    "                for img_name in tqdm(os.listdir(class_source), desc=f\"Processing {class_name}\"):\n",
    "                    img_path = class_source / img_name\n",
    "                    img = cv2.imread(str(img_path))\n",
    "                    if img is None:\n",
    "                        logger.warning(f\"Failed to read image {img_path}\")\n",
    "                        continue\n",
    "                    cropped_img = self.crop_image(img)\n",
    "                    if cropped_img is not None:\n",
    "                        resized_img = cv2.resize(cropped_img, (240, 240))\n",
    "                        save_path = class_target / f\"{j}.jpg\"\n",
    "                        cv2.imwrite(str(save_path), resized_img)\n",
    "                        j += 1\n",
    "                        image_count += 1\n",
    "                logger.info(f\"Processed {j} images for class {class_name}\")\n",
    "            if image_count == 0:\n",
    "                logger.error(\"No images were processed; check source directories.\")\n",
    "                raise ValueError(\"No images processed during cleaning.\")\n",
    "            logger.info(f\"Total images processed: {image_count}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing images: {e}\")\n",
    "            raise\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"Executes the full cleaning pipeline.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting data cleaning pipeline...\")\n",
    "            self.validate_directories()\n",
    "            self.create_output_directories()\n",
    "            self.process_images(self.train_dir, self.cropped_train_dir)\n",
    "            self.process_images(self.test_dir, self.cropped_test_dir)\n",
    "            logger.info(\"Data cleaning pipeline completed.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data cleaning failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca974eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "        config = DataConfigurationManager()\n",
    "        cleaning_config = config.get_data_cleaning_config()\n",
    "        cleaner = DataCleaning(config=cleaning_config)\n",
    "        cleaner.clean()\n",
    "except Exception as e:\n",
    "        logger.error(f\"Data cleaning failed: {e}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuroScan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
